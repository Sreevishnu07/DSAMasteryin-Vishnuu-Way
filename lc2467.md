**Breakdown 1:**
So this question was actually really challenging, the question itself is not that tough since the problem statement is long. 
You just have to make sure you go point by point understanding. 
The key points are:
Alice always starts from 0, and Bob moves towards zero.
We are least concerned with the amount Bob would incur as the question is clearly about the max income of Alice.
Other three most important points are:
If Alice reaches before Bob, then Alice would take all the amount.
If on the same time, then Alice would take half of the amount.
In case Bob reaches before Alice, Alice would get nothing.

**Breakdown 2:**
So there are multiple ways pertaining to BFS, DFS. I felt the double DFS to be pretty straightforward. 
Again, there are two ways you can go about it:

First way: Use one DFS to find the distance of Alice from the source and build up the parents, 
then use a for loop to construct Bob's path along the parent array. Modify amounts based on the arrival times. 
Another DFS to traverse the paths of Alice (obviously because there are many) but then choose the optimal one (maximum).

Second way: Use one DFS to find Bob's path, store the arrival times in an unordered map. 
Then use the next DFS for Alice's path from 0 and dynamically calculate profit using the hash map we made (pretty intuitive too).

Now comes one another alternate method:
Use DFS to find Bob's path, recording the times. Then, as we need to consider all possibilities to build up the efficient path, 
we can go for BFS from 0 to get to the max income after the comparisons with Bob's time.

Then comes the final and a brilliant solution of just using a single DFS. As the DFS reaches Bob, 
the recursion naturally gets back towards node 0, which allows the parent-child connections to be recorded without 
needing an explicit extra traversal. The point is, DFS while backtracking is definitely going to get back to 0, so it gives you that info already.

Though it was an awesome solution, still the double DFS is faster in practice at times, 
as you go for the iterative lookup for parent. Also, mainly I felt in single DFS, one DFS has to handle a lot of work (Bob, Alice put together). 
That's definitely going to increase the stack frame operations. In double DFS, we get the advantage of each DFS for a specific purpose, so yeah, that helps. 
This was a really beautiful question—it tests you to a great extent.

**Breakdown 3:**
Just for an addition to the most profitable question, it's one of the most important questions to practice, 
understanding all different combinations of DFS, BFS you can apply here.

The key is:
You can either start with DFS to get the path for Bob and record times in an unordered map.
Why DFS here? Pretty straightforward—it's a tree basically (as it's clearly mentioned in the question).
 As you know, the fundamental property of a tree is there is only one unique path from a node to a different node. 
 So it's definitely going to find the path from the source to 0 where Bob has to reach.

Then you can go for BFS for Alice (why BFS? Again, pretty straightforward, right? Because Alice, unlike Bob, 
has multiple paths to check to find the ultimately optimal one which gives her max income. So BFS can be a choice straight up).

The key here is you match the unordered map you made for Bob whenever Alice visits a node Bob visited. 
In case the time for Alice is less than Bob's reaching time, then Alice gets everything. If both are equal, then remember Alice gets only half. But you would have guessed the problem with this approach, which is the extra space for a queue (in BFS) and don't forget the system's stack at the worst case for recursion, which goes till n too. So it's inefficient in terms of space.

So the next two approaches for DFS I loved both, but one of them was my ultimate favorite:
Basically, the first double DFS approach is you do a DFS to construct Bob's path with unordered map storing the times.
Then, the next DFS (again intuitive, I guess) goes through all paths with backtracking and takes the max out of it. 
And remember, whenever Alice visits a node Bob visited, you go for a condition check as I mentioned in the first approach. 
The whole point of unordered map was that.

Now, this solution is definitely better in terms of space, but we still have the lookup overhead for unordered map. 
So what can be done? The problem, if you see, is Bob's time recording. So why don't we go for a vector (array) explicitly? Now, how do we do that?

**Breakdown 4:**
So now comes my most favorite approach, which is:

You do DFS for Alice, record the parents of each node, and then use this information to get into a for loop 
that will trace the parents from the source to get to 0, where Bob wants to go. (Remember, it's a tree, so only one valid path. We need not worry.)

In this process, we keep checking the conditions as we usually do.
Finally, a DFS to get the max income path.
Again, the key here is:
You return the amount as is if it's a leaf node.
But in case it's an internal node, then you add up the amount of that node with the amount from the children. 
This actually is the key while backtracking because you need the maximum income.

I would strongly suggest to work it out; otherwise, just getting it without understanding wouldn't be efficient. 
So in this approach, we have managed efficiently without the unordered map lookup overhead, and also, I felt it was better.

And you see, the DFS's are used only for specific purposes, thereby reducing the stack frame operations. 
This is the exact reason why it's faster in practice than the single DFS approach.

Lastly, but not the least, we have our single DFS approach. 
I felt it's a small nuance, but a brilliant way to construct the logic. 
The point is, naturally, DFS does the backtracking and Bob's unique path will be traversed. So, do we need two DFS? 
The answer is no. It can be done parallelly, but there are many things to be careful here. We want to get the min distances for Bob while backtracking, 
and from there we also have to make sure we return the max path, keeping in mind the conditions to be applied.

Again, this approach is damn brilliant, but if not handled properly, 
it would be harder to debug. It's fast as well, but you would ask, 
it's counterintuitive to say double DFS is fast in practice. 
Now, perfect thought process, and yes, it's redundant to have double DFS when you can do it with one DFS. 
But you see, why double DFS? The second approach I said is fast primarily because the DFS has no much extra work to be done, 
thereby reducing each stack frame operation. But in single DFS, we have to dynamically do multiple tasks: getting the distances for Bob, 
checking conditions simultaneously, and finding the max income. So, a lot of stack frame operations, thereby making it slightly slower.

But then, understanding the approach is the core, in my opinion.