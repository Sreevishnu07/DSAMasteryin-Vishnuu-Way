## Breakdown 1: 
So this question was actually really challenging, the question itself is not that tough since the problem statement is long u just have to make sure u go point by point understanding,the key points are Alice always starts from 0,and Bob moves towards zero we are least concerned with amount bob would incur as the question is clearly about max income of Alice,other three most important points are if Alice reaches before Bob then Alice would take all the amount,if on same time then Alice would take half of the amount,and incase Bob reaches before Alice,Alice would get nothing..

## Breakdown 2:
So there are multiple ways pertaining to bfs,dfs I felt the double dfs to be pretty stforward again there are two ways you can go about it one is use one dfs to find the distance of Alice from src and build up the parents then use a for loop to construct bob's path along the parent array,modify amounts based on the arrival times,another dfs to traverse the paths of Alice(obvsly cos there are many) but then choose the optimal one(maximum).. so now the second way to go about is, use one dfs to find Bob's path,store the arrival times in an unordered map then the next dfs for Alice's path from 0 and to dynamically calculate profit using the hash map we made(pretty intuitive too),now comes one another alternate method which is use dfs to find Bob's path recording the times then as we need to consider all possibility to build up the efficient path we can go for bfs from 0 to get to the max income after the comparisons with Bob's time then comes the final and a brilliant solution of just using a single dfs as if dfs reaches bob, the recursion naturally gets back towards node 0, which allows the parent-child connections to be recorded without needing an u say explicit extra traversal,the point is dfs while backtracking is definitely gona get back to 0,so it gives u that info already,though it was one awesome of a solution still the double dfs is faster in practice at times,as you go for the iterative lookup for parent and also mainly i felt in single dfs one dfs has to handle a lot of work Bob,Alice put together thats definitely going to increase the stack frame operations,in double dfs we get the advantage of each dfs for a specific purpose so yea that helps,this was a really beautiful q tests u to a great extent..

##Breakdown-3:
Just for an addition to most profitable question,its one of the most important qs to practice,understanding all different combinations of dfs,bfs u can apply here,the key is u can either start with dfs to get the path for bob and record times in an unordered map and now why dfs here pretty stforward its a tree basically(as its clearly mentioned in the question) as u know the fundamental property of a tree is there is only one path(unique) from a node to a different node so its definitely going to find the path from source to 0 where Bob has to reach,then you can go for bfs for alice(why bfs? again pretty straightforward right,cos Alice unlike bob has multiple paths to check to find the ultimately optimal one which gives her max income so bfs can be a choice straight up) and the key here is u match the unordered_map u made for bob whenever Alice visits a node bob visited incase time for alice is less than Bob's reaching time then alice gets everything if both are equal then remember Alice gets only half,but u would have guessed the problem with this approach which is the extra space for a queue(in bfs) and don't forget the system's stack at the worst case for recursion goes till n too so its like inefficient in terms of space so next two approaches for dfs I loved both but one of it was my ultimate fav,basically the first double dfs approach is you do a dfs to construct Bob's path with unordered_map storing the times then the next dfs(again intuitive I guess) to go through all paths with backtracking and taking the max out of it and remember whenever Alice visits a node Bob visited u go for a condition check as I mentioned in the first approach,the whole point of unordered_map was that,now this solution is definitely better in terms of space but we still have the lookup overhead for unordered_map so what can be done? the problem if u see is Bob's time recording so why don't we go for a vector(Array) explicitly now how do we do that?


##Breakdown-4
So now comes my most fav approach which is u do dfs for Alice record the parents of each node and then use this information to get into a for loop that will trace the parents from src to get to 0 where bob wants to go(remember its a tree so only one valid path so we need not worry) and in this process we keep checking the conditions as we usually do then finally a dfs to get the max income path,again the key here is u return the amount as is if its a leaf node but incase its a internal node then you add up the amount of that node with the amount from the children(this actually is the key while backtracking) because u need the maximum income,would strongly suggest to work it out otherwise just getting it without understanding wouldn't be efficient,so this approach we have managed efficiently without the unordered_map lookup overhead and also I felt it was damn,and u see the dfs's are used only for specific purposes thereby reducing the stack frame operations(this is the exact reason why its faster in practice than the single dfs approach) and last but not the least we have our single dfs approach I felt its a small nuance but a brilliant way to construct the logic,the point is naturally dfs does the backtracking and Bob's unique path will be traversed so do we need two dfs answer is no,it can be done parallely but there are many things to be careful here,we want to get the min distances for bob while backtracking and from there we also have to max sure we return the max path keeping in mind the conditions to be applied again this approach is damn brilliant but if not handled properly it would be harder to debug,and its fast as well but u would ask its counter-intuitive to say double dfs is fast in practice now perfect thought process and yes its redundant to have double dfs when u can do it with one dfs,but u see why double dfs the second approach i said is fast primarily because the dfs has no much extra work to be done thereby reducing each stack frame operations but in single dfs we have to dynamically do multiple tasks getting the distances for Bob,checking conditions simultaneously,and finding the max income so a lot of stackframe operations thereby making it slightly slow,but then understanding the approach is the core in my opinion.